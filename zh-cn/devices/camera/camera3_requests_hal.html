<html devsite><head>
    <title>HAL 子系统</title>
    <meta name="project_path" value="/_project.yaml"/>
    <meta name="book_path" value="/_book.yaml"/>
  </head>
  <body>
  <!--
      Copyright 2017 The Android Open Source Project

      Licensed under the Apache License, Version 2.0 (the "License");
      you may not use this file except in compliance with the License.
      You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
  -->

<h2 id="requests">请求</h2>
<p>应用框架会针对捕获的结果向相机子系统发出请求。一个请求对应一组结果。请求包含有关捕获和处理这些结果的所有配置信息。其中包括分辨率和像素格式；手动传感器、镜头和闪光灯控件；3A 操作模式；RAW 到 YUV 处理控件；以及统计信息的生成等。这样一来，便可更好地控制结果的输出和处理。一次可发起多个请求，而且提交请求时不会出现阻塞。请求始终按照接收的顺序进行处理。</p>
  <img src="images/camera_model.png" alt="相机请求模型" id="figure1"/>
  <p class="img-caption">
  <strong>图 1.</strong>  相机模型</p>
<h2 id="hal-subsystem">HAL 和相机子系统</h2>
<p>相机子系统包括相机管道中组件的实现，例如 3A 算法和处理控件。相机 HAL 为您提供了用于实现您的这些组件版本的接口。为了保持多个设备制造商和图像信号处理器（ISP，也称为相机传感器）供应商之间的跨平台兼容性，相机管道模型是虚拟的，且不直接对应于任何真正的 ISP。不过，它与真正的处理管道足够相似，因此您可以有效地将其映射到硬件。此外，它足够抽象，可支持多种不同的算法和运算顺序，而不会影响质量、效率或跨设备兼容性。</p>
<p>相机管道还支持应用框架可以启动来开启自动对焦等功能的触发器。它还会将通知发送回应用框架，以通知应用自动对焦锁定或错误等事件。</p>
  <img src="images/camera_hal.png" alt="相机硬件抽象层" id="figure2"/>
  <p class="img-caption">
  <strong>图 2.</strong> 相机管道</p>
<p>请注意，上图所示的一些图像处理块在初始版本中没有明确定义。相机管道做出以下假设：</p>
<ul>
  <li>RAW Bayer 输出在 ISP 内部不经过任何处理。</li>
  <li>统计信息根据原始传感器数据生成。</li>
  <li>将原始传感器数据转换为 YUV 的各种处理块按任意顺序排列。</li>
  <li>当显示多个刻度和剪裁单元时，所有缩放器单元共享输出区域控件（数字缩放）。不过，每个单元都可能具有不同的输出分辨率和像素格式。</li>
</ul>
<p><strong>API 用途摘要</strong><br />
下面简要介绍了使用 Android Camera API 的步骤。有关这些步骤（包括 API 调用）的详细说明，请参阅“启动和预期操作顺序”部分。</p>
<ol>
  <li>监听和枚举相机设备。</li>
  <li>打开设备并连接监听器。</li>
  <li>配置目标使用情形的输出（如静态捕获、录制等）。</li>
  <li>为目标使用情形创建请求。</li>
  <li>捕获/重复请求和连拍。</li>
  <li>接收结果元数据和图片数据。</li>
  <li>切换使用情形时，返回到第 3 步。</li>
</ol>
<p><strong>HAL 操作摘要</strong></p>
<ul>
  <li>捕获的异步请求来自于框架。</li>
  <li>HAL 设备必须按顺序处理请求。对于每个请求，均生成输出结果元数据以及一个或多个输出图像缓冲区。</li>
  <li>请求和结果以及后续请求引用的信息流遵守先进先出规则。</li>
  <li>指定请求的所有输出的时间戳必须完全相同，以便框架可以根据需要将它们匹配在一起。</li>
  <li>所有捕获配置和状态（不包括 3A 例程）都包含在请求和结果中。</li>
</ul>
<img src="images/camera-hal-overview.png" alt="相机 HAL 概览" id="figure3"/>
<p class="img-caption">
  <strong>图 3.</strong>  相机 HAL 概览</p>
<h2 id="startup">启动和预期操作顺序</h2>
<p>本部分详细说明了使用 Camera API 时应遵循的步骤。有关 HIDL 接口的定义，请参阅 <a href="https://android.googlesource.com/platform/hardware/interfaces/+/master/camera/">platform/hardware/interfaces/camera/</a>。</p>

<h3 id="open-camera-device">枚举、打开相机设备并创建有效会话</h3>
<ol>
  <li>初始化后，框架开始监听实现 <code><a href="https://android.googlesource.com/platform/hardware/interfaces/+/master/camera/provider/2.4/ICameraProvider.hal">ICameraProvider</a></code> 接口的任何现有相机提供程序。如果存在一个或多个此类提供程序，框架将尝试建立连接。</li>
  <li>框架通过 <code>ICameraProvider::getCameraIdList()</code> 枚举相机设备。</li>
  <li>框架通过调用相应的 <code>ICameraProvider::getCameraDeviceInterface_VX_X()</code> 来实例化一个新的 <code>ICameraDevice</code>。</li>
  <li>框架调用 <code>ICameraDevice::open()</code> 来创建一个新的有效捕获会话 ICameraDeviceSession。</li>
</ol>

<h3 id="use-active-session">使用有效相机会话</h3>

<ol>
  <li>框架调用 <code>ICameraDeviceSession::configureStreams()</code> 并传入到 HAL 设备的输入/输出流列表。</li>
  <li>框架通过调用 <code>ICameraDeviceSession::constructDefaultRequestSettings()</code> 来为某些使用情形请求默认设置。这可能会在 <code>ICameraDevice::open</code> 创建 <code>ICameraDeviceSession</code> 之后的任何时间发生。
  </li>
  <li>框架通过基于某一组默认设置的设置以及框架之前注册的至少一个输出流来构建第一个捕获请求并将其发送到 HAL。此请求通过 <code>ICameraDeviceSession::processCaptureRequest()</code> 发送到 HAL。HAL 必须阻止此调用返回，直到准备好发送下一个请求为止。</li>
  <li>框架继续提交请求并根据需要调用 <code>ICameraDeviceSession::constructDefaultRequestSettings()</code> 以获取其他使用情形的默认设置缓冲区。</li>
  <li>当请求捕获开始（传感器开始曝光以进行捕获）时，HAL 会调用 <code>ICameraDeviceCallback::notify()</code> 并显示 SHUTTER 消息，包括帧号和开始曝光的时间戳。此通知回调不必在对请求第一次调用 <code>processCaptureResult()</code> 之前发生，但直到针对相应的捕获调用 <code>notify()</code> 之后，才会向应用提供有关该捕获的结果。
  </li>
  <li>经过一定的管道延迟后，HAL 开始使用 <code>ICameraDeviceCallback::processCaptureResult()</code> 将完成的捕获返回到框架。这些捕获按照与提交请求相同的顺序返回。一次可发起多个请求，具体取决于相机 HAL 设备的管道深度。</li>
</ol>

<p>一段时间后，会出现以下某种情况：</p>
  <ul>
  <li>框架可能会停止提交新的请求，等待现有捕获完成（所有缓冲区都已填充，所有结果都已返回），然后再次调用 <code>ICameraDeviceSession::configureStreams()</code>。这会重置相机硬件和管道，以获得一组新的输入/输出流。可重复使用先前配置中的部分信息流。如果至少还有一个已注册的输出流，则框架将从发送到 HAL 的第一个捕获请求继续。（否则，需要先调用 <code>ICameraDeviceSession::configureStreams()</code>。）</li>
  <li>框架可能会调用 <code>ICameraDeviceSession::close()</code> 以结束相机会话。当框架中没有其他处于有效状态的调用时，可能随时会调用此函数；不过，在所有发起的捕获完成（所有结果都已返回，所有缓冲区都已填充）之前，调用可能会阻塞。<code>close()</code> 调用返回后，不允许再从 HAL 对 <code>ICameraDeviceCallback</code> 进行调用。一旦进行 <code>close()</code> 调用，框架便不能再调用其他任何 HAL 设备函数。</li>
  <li>在发生错误或其他异步事件时，HAL 必须调用 <code>ICameraDeviceCallback::notify()</code> 并返回相应的错误/事件消息。从严重的设备范围错误通知返回后，HAL 的行为方式应像对其调用了 <code>close()</code> 一样。但是，HAL 必须在调用 <code>notify()</code> 之前取消或完成所有待处理的捕获，以便在调用 <code>notify()</code> 并返回严重错误时，框架不会收到来自设备的更多回调。在 <code>notify()</code> 方法从严重错误消息返回后，<code>close()</code> 之外的方法应返回 -ENODEV 或 NULL。</li>
  </ul>
<img src="images/camera-ops-flow.png" alt="相机操作流程" id="figure4" width="485"/>
<p class="img-caption">
  <strong>图 4.</strong> 相机操作流程
</p>
<h2 id="hardware-levels">硬件级别</h2>
<p>相机设备可以根据其功能实现多个硬件级别。有关详情，请参阅<a href="https://developer.android.com/reference/android/hardware/camera2/CameraCharacteristics#INFO_SUPPORTED_HARDWARE_LEVEL">支持的硬件级别</a>。</p>
<h2 id="interaction">应用捕获请求、3A 控件和处理管道之间的交互</h2>
<p>根据 3A 控件块中的设置，相机管道会忽略应用捕获请求中的某些参数，而改用 3A 控件例程提供的值。例如，启用自动曝光后，传感器的曝光时间、帧时长和感光度参数由平台 3A 算法控制，所有应用指定的值都会被忽略。必须在输出元数据中报告由 3A 例程为帧选择的值。下表描述了 3A 控件块的不同模式以及由这些模式控制的属性。有关这些属性的定义，请参阅 <a href="https://android.googlesource.com/platform/system/media/+/master/camera/docs/docs.html">platform/system/media/camera/docs/docs.html</a> 文件。</p>
<table>
  <tbody><tr>
    <th>参数</th>
    <th>状态</th>
    <th>受控制的属性</th>
  </tr>
  <tr>
    <td>android.control.aeMode</td>
    <td>OFF</td>
    <td>无</td>
  </tr>
  <tr>
    <td></td>
    <td>ON</td>
    <td>android.sensor.exposureTime
android.sensor.frameDuration
android.sensor.sensitivity android.lens.aperture（如果支持的话）
android.lens.filterDensity（如果支持的话）</td>
  </tr>
  <tr>
    <td></td>
    <td>ON_AUTO_FLASH</td>
    <td>均已开启，还有 android.flash.firingPower、android.flash.firingTime 和 android.flash.mode</td>
  </tr>
  <tr>
    <td></td>
    <td>ON_ALWAYS_FLASH</td>
    <td>与 ON_AUTO_FLASH 相同</td>
  </tr>
  <tr>
    <td></td>
    <td>ON_AUTO_FLASH_RED_EYE</td>
    <td>与 ON_AUTO_FLASH 相同</td>
  </tr>
  <tr>
    <td>android.control.awbMode</td>
    <td>OFF</td>
    <td>无</td>
  </tr>
  <tr>
    <td></td>
    <td>WHITE_BALANCE_*</td>
    <td>android.colorCorrection.transform。如果 android.colorCorrection.mode 为 FAST 或 HIGH_QUALITY，则进行特定于平台的调整。</td>
  </tr>
  <tr>
    <td>android.control.afMode</td>
    <td>OFF</td>
    <td>无</td>
  </tr>
  <tr>
    <td></td>
    <td>FOCUS_MODE_*</td>
    <td>android.lens.focusDistance</td>
  </tr>
  <tr>
    <td>android.control.videoStabilization</td>
    <td>OFF</td>
    <td>无</td>
  </tr>
  <tr>
    <td></td>
    <td>ON</td>
    <td>可调整 android.scaler.cropRegion 来实现视频防抖</td>
  </tr>
  <tr>
    <td>android.control.mode</td>
    <td>OFF</td>
    <td>AE、AWB 和 AF 处于停用状态</td>
  </tr>
  <tr>
    <td></td>
    <td>AUTO</td>
    <td>单独使用 AE、AWB 和 AF 设置</td>
  </tr>
  <tr>
    <td></td>
    <td>SCENE_MODE_*</td>
    <td>可替换上述所有参数。各个 3A 控件均处于停用状态。</td>
  </tr>
</tbody></table>
<p>在图 2 中，图像处理块中的控件都以类似的原理操作，并且每个块一般都具有 3 种模式：</p>
<ul>
  <li>OFF：该处理块处于停用状态。无法停用去马赛克、色彩校正和色调曲线调整块。</li>
  <li>FAST：与 OFF 模式相比，在这种模式下，处理块可能不会降低输出帧速率，但是考虑到限制条件，它应该会产生能够产生的最优质输出。通常，该模式会用于预览或视频录制模式，或用于连拍静态图像。在一些设备上，该模式可能等同于 OFF 模式（进行任何处理都会降低帧速率）；而在另外一些设备上，该模式可能等同于 HIGH_QUALITY 模式（最佳质量仍不会降低帧速率）。</li>
  <li>HIGH_QUALITY：在这种模式下，处理块应尽可能产生最优质结果，根据需要降低输出帧速率。通常，该模式会用于拍摄优质静态图像。一些块包括可以被选中的手动控件（而非 FAST 或 HIGH_QUALITY）。例如，色彩校正块支持颜色变换矩阵，而色调曲线调整支持任意的全局色调映射曲线。</li>
</ul>
  <p>相机子系统可以支持的最大帧速率受到多种因素的影响：</p>
<ul>
  <li>所请求的输出图像流的分辨率</li>
  <li>成像器上像素组合/跳过模式的可用性</li>
  <li>成像器接口的带宽</li>
  <li>各种 ISP 处理块的带宽</li>
</ul>
<p>由于这些因素在不同的 ISP 和传感器之间可能有很大差异，因此相机 HAL 接口会设法将带宽限制抽象为尽可能简单的模型。显示的模型具有以下特性：</p>
<ul>
  <li>考虑到应用的请求输出流大小，图像传感器始终配置为输出尽可能最小的分辨率。最小分辨率定义为至少与请求的最大输出流一样大。</li>
  <li>因为任何请求都可能使用当前配置的任意或所有输出流，所以传感器和 ISP 必须配置为支持将单个捕获同时扩展到所有信息流。</li>
  <li>对于不包含 JPEG 流的请求，JPEG 流表现得像经过处理的 YUV 流一样；在直接引用它们的请求中，它们用作 JPEG 流。</li>
  <li>JPEG 处理器可以并行运行到相机管道的剩余部分，但不能一次处理多个捕获。</li>
</ul>

</body></html>