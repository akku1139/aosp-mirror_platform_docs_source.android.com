<html devsite>
  <head>
    <title>SurfaceTexture</title>
    <meta name="project_path" value="/_project.yaml" />
    <meta name="book_path" value="/_book.yaml" />
  </head>
  <body>
  <!--
      Copyright 2017 The Android Open Source Project

      Licensed under the Apache License, Version 2.0 (the "License");
      you may not use this file except in compliance with the License.
      You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
  -->



<p>A SurfaceTexture is a combination of a surface and an OpenGL ES (GLES)
texture. SurfaceTextures are used to provide surfaces that output to GLES
textures.</p>

<p>A SurfaceTexture contains a BufferQueue for which
apps are the consumer. The <code>onFrameAvailable()</code> callback
notifies apps when the producer queues a new buffer. Then, apps call
<code>updateTexImage()</code>, which releases the previously held buffer,
acquires the new buffer from the queue, and makes EGL calls to make the
buffer available to GLES as an external texture.</p>

<h2 id="ext_texture">External GLES textures</h2>

<p>An external GLES texture (<code>GL_TEXTURE_EXTERNAL_OES</code>) differ
from traditional GLES textures (<code>GL_TEXTURE_2D</code>) in the following
ways:</p>

<ul>
  <li>External textures render textured polygons directly from data received
    from BufferQueue.</li>
   <li>External texture renderers are configured differently than
    traditional GLES texture renderers.</li>
  <li>External textures can't perform all traditional GLES texture
    activities.</li>
</ul>

<p>The main benefit of external textures is
their ability to render directly from BufferQueue data. SurfaceTexture sets the
consumer usage flags to <code>GRALLOC_USAGE_HW_TEXTURE</code> when it creates
BufferQueues for external textures to ensure that the data in the buffer is
recognizable by GLES.</p>

<p>Because SurfaceTexture interacts with an EGL context, an app can only call
its methods while the EGL context that owns the texture is current on the
calling thread. For more information see the <a
href="https://developer.android.com/reference/android/graphics/SurfaceTexture"
class="external">SurfaceTexture</a> class documentation.</p>

<h2 id="time_transforms">Timestamps and transformations</h2>

<p>SurfaceTexture includes the <code>getTimeStamp()</code> method, which
retrieves a timestamp, and <code>getTransformMatrix()</code> method, which
retrieves a transformation matrix. Calling <code>updateTexImage()</code>
sets both the timestamp and the transformation matrix. Each buffer that
BufferQueue passes includes transformation parametes and a timestamp.</p>

<p>Transformation parameters are useful for efficiency. In some cases,
source data might be in the incorrect orientation for the consumer.
Instead of rotating the data before sending it to the consumer, send the data in
its orientation with a transform that corrects it. The transformation
matrix can be merged with other transformations when the data is used,
minimizing overhead.</p>

<p>The timestamp is useful for buffer sources that are time dependent. For
example, when <code>setPreviewTexture()</code> connects
the producer interface to the output of the camera, frames from the camera can
be used to create a video. Each frame needs to have a presentation
timestamp from when the frame was captured, not from when the app received the
frame. The camera code sets the timestamp provided with the buffer,
resulting in a more consistent series of timestamps.</p>

<h2 id="continuous_capture">Case study: Grafika's continuous capture</h2>

<p><a href="https://github.com/google/grafika/blob/master/app/src/main/java/com/android/grafika/ContinuousCaptureActivity.java"
class="external">Grafika's continuous capture</a> involves recording frames
from a device's camera and displaying those frames on screen.
To record frames, create a surface with the
<a href="https://www.google.com/url?sa=D&q=https%3A%2F%2Fdeveloper.android.com%2Freference%2Fandroid%2Fmedia%2FMediaCodec"
class="external">MediaCodec</a> class's
<code>createInputSurface()</code> method and pass the surface to the camera. To
display frames, create a SurfaceView and pass the surface to
<code>setPreviewDisplay()</code>. However, recording frames and displaying
them at the same time is a more involved process.</p>

<p>The <em>continuous capture</em> activity displays video from the camera as
video is being recorded. In this case, encoded video is written to a
circular buffer in memory that can be saved to disk at any time.</p>

<p>This flow involves three BufferQueues:</p>
<ul>
<li><strong>App</strong> &mdash; The app uses a SurfaceTexture to receive
frames from the camera, converting them to an external GLES texture.</li>
<li><strong>SurfaceFlinger</strong> &mdash; The app declares a SurfaceView
to display the frames.</li>
<li><strong>MediaServer</strong> &mdash; Configure a MediaCodec encoder with an
input surface to create the video.</li>
</ul>

<img src="images/continuous_capture_activity.png" alt="Grafika continuous
capture activity" />

<p>In the figure below, the arrows indicate data propagation from the camera.
BufferQueues are in color (producers are teal, consumers are green).</p>

<p class="img-caption"><strong>Figure 1.</strong> Grafika's continuous capture
activity.</p>

<p>Encoded H.264 video goes to a circular buffer in RAM in the app process.
When a user presses the capture button, the <code>MediaMuxer</code> class
writes the encoded video to an MP4 file on disk.</p>

<p>All the BufferQueues are handled with a single EGL context in the
app while the GLES operations are performed on the UI thread. The handling of
encoded data (managing a circular buffer and writing it to disk) is done
on a separate thread.</p>

<aside class="warning"><strong>Warning:</strong> If the video encoder locks up
and blocks a dequeueing buffer the app becomes unresponsive.</aside>

<aside class="note"><strong>Note:</strong> Doing SurfaceView rendering on the UI
thread is discouraged, but it's used in this case study for simplicity.
More complex rendering should use a dedicated thread to isolate the GLES context
and minimize interference with the rendering of another app's UI.</aside>

<p>SurfaceView's <code>surfaceCreated()</code> callback creates the EGLContext
and EGLSurfaces for the display and the video encoder. When a new frame arrives,
SurfaceTexture performs four activities:</p>

<ol>
  <li>Acquires the frame.</li>
  <li>Makes the frame available as a GLES texture.</li>
  <li>Renders the frame with GLES commands.</li>
  <li>Forwards the transform and timestamp for each EGLSurface.</li>
</ol>

<p>The encoder thread then pulls the encoded output from MediaCodec and stashes
it in memory.</p>

<h2 id="st_vid_play">Secure texture video playback</h2>

<p>Android supports GPU post-processing of protected video content. This
lets apps use the GPU for complex, nonlinear video effects (such as warps),
mapping protected video content onto textures for use in general graphics scenes
(for example, using GLES), and virtual reality (VR).</p>

<img src="images/graphics_secure_texture_playback.png" alt="Secure Texture Video Playback" />
<p class="img-caption"><strong>Figure 2.</strong> Secure texture video playback</p>

<p>Support is enabled using the following two extensions:</p>
<ul>
<li><strong>EGL extension</strong> &mdash;
(<code><a
href="https://www.khronos.org/registry/egl/extensions/EXT/EGL_EXT_protected_content.txt"
class="external">EGL_EXT_protected_content</code></a>)
Enables the creation of protected GL contexts and surfaces, which can both
operate on protected content.</li>
<li><strong>GLES extension</strong> &mdash;
(<code><a href="https://www.khronos.org/registry/gles/extensions/EXT/EXT_protected_textures.txt"
class="external">GL_EXT_protected_textures</code></a>)
Enables tagging textures as protected so they can be used as framebuffer texture
attachments.</li>
</ul>

<p>Android enables SurfaceTexture and ACodec
(<code>libstagefright.so</code>) to send protected content even if
the window's surface doesn't queue to SurfaceFlinger
and provide a protected video surface for use within a protected context. This
is done by setting the protected consumer bit
(<code>GRALLOC_USAGE_PROTECTED</code>) on surfaces created in a protected
context (verified by ACodec).</p>

<p>Secure texture video playback sets the foundation for strong DRM
implementation in the OpenGL ES environment. Without a strong DRM implementation,
such as Widevine Level 1, many content providers don't allow rendering of
their high-value content in the OpenGL ES environment, preventing important VR
use cases such as watching DRM-protected content in VR.</p>

<p>AOSP includes framework code for secure texture video playback. Driver
support is up to OEMs. Device implementers must implement
<code>EGL_EXT_protected_content</code> and
<code>GL_EXT_protected_textures extensions</code>. When using your own codec
library (to replace <code>libstagefright</code>), note the changes in
<code>/frameworks/av/media/libstagefright/SurfaceUtils.cpp</code> that allow
buffers marked with <code>GRALLOC_USAGE_PROTECTED</code> to be sent to
ANativeWindows (even if ANativeWindow doesn't queue directly to the window
composer) as long as the consumer usage bits contain
<code>GRALLOC_USAGE_PROTECTED</code>. For detailed documentation on implementing
the extensions, refer to the Khronos registries
(<a
href="https://www.khronos.org/registry/egl/extensions/EXT/EGL_EXT_protected_content.txt"
class="external">EGL_EXT_protected_content</a>,
and
<a href="https://www.khronos.org/registry/gles/extensions/EXT/EXT_protected_textures.txt"
class="external">GL_EXT_protected_textures</a>).</p>

<aside class="note"><strong>Note:</strong> Device implementers may need to
make hardware changes to ensure that protected memory mapped onto the GPU
remains protected and unreadable by unprotected code.</aside>

  </body>
</html>
