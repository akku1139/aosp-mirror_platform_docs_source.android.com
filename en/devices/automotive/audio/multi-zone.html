<html devsite>
  <head>
    <title>Multi-Zone Audio</title>
    <meta name="project_path" value="/_project.yaml" />
    <meta name="book_path" value="/_book.yaml" />
  </head>
  {% include "_versions.html" %}
  <body>
  <!--
      Copyright 2018 The Android Open Source Project

      Licensed under the Apache License, Version 2.0 (the "License");
      you may not use this file except in compliance with the License.
      You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.
  -->


<p>
  While Android {{ androidPVersionNumber }} does not support multi-zone audio,
  the Android audio teams have explored several possible approaches to
  multi-zone audio. This section provides details on some of these approaches
  that might be helpful to system implementers setting out to build rear-seat
  entertainment (RSE) solutions.
</p>

<h2 id=user-cases>Use cases</h2>

<ul>
  <li>Radio in rear seats plays simultaneously with different media sources in
  front seats.</li>
  <li>Front seat passenger hears a different media source than the driver (e.g.
  passenger plays a game on their own screen while driver views navigation on
  the main screen).</li>
  <li>Four different, independent audio zones: Driver, front seat passenger,
  rear seat 1, rear-seat 2.</li>
</ul>

<h2 id="limitations">Limitations</h2>

<p>
  Android {{ androidPVersionNumber }} doesn't support multiple audio stacks
  (zones) or different priorities natively due to the following limitations:
</p>

<ul>
  <li>Android {{ androidPVersionNumber }} does not provide APIs that enable
  applications to target a specific zone. Instead, applications must target the
  audio type (media, announcement, etc.), which is selected from a pre-defined
  set provided by Android. For example, Android does not currently support
  defining the audio type as <strong>media</strong> for target <strong>zone
  2</strong>.</li>
  <li>Physical Streams (provided by the AudioFlinger/internal mixer) do not
  transport Context information (e.g. tagging within Logical Streams) after the
  mixing; preventing the Audio HAL from routing specific Logical Streams to
  different zones.</li>
</ul>

<h2 id="scenario-multiple-instances">Scenario: Use multiple instances</h2>

<p>
  This scenario uses multiple instances of Android automotive to effect
  multi-zone audio.
</p>

<ul>
  <li>Each zone has its own Android automotive instance that independently
  manages zone content. Hardware below the HAL combines and coordinates the
  output of multiple instances.</li>
  <li>Instances exist on distinct hardware (i.e. tablets in the rear seat) or
  share physical hardware via a hypervisor.</li>
  <li>Output is statically assigned to vehicle speakers using a single primary
  zone or dynamic assignments are made below the HAL.</li>
  <li>First-party party apps (installed in every instance) collaborate via a
  proprietary protocol to coordinate and route sounds to specific zones.
  Alternatively, use ChromeCast functionality to communicate across different
  instances and even devices.</li>
</ul>

<h2 id="scenario-target-secondary-zones">Scenario: Target secondary zones</h2>

<p>
  This scenario uses first-party applications to explicitly target secondary
  zones (which are ignored by Android).
</p>

<ul>
  <li>OEM defines additional output audio device ports in
  <code>audio_policy_configuration.xml</code>.</li>
  <li>First-party applications that implicitly know the vehicle configuration
  can enumerate the available output ports and explicitly target any one of them
  using the <code>AudioTrack.setPrefereceDevice()</code> API.</li>
</ul>

<h2 id="scenario-audio-policy-rules">Scenario: Use audio policy rules</h2>

<p>
  This scenario uses audio policy rules to dynamically add route-specific UIDs
  to additional audio devices.
</p>

<ul>
  <li>The audio routing engine defines routing rules based on the UID of the
  requesting application.</li>
  <li>A system-level service or launcher adds rules to send the output of a
  specific application (UID) to a specific device associated with a secondary
  zone.</li>
  <li>These specific devices are defined in addition to those provided for
  routing of the predefined audio contexts.</li>
</ul>

</body>
</html>